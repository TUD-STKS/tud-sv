{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 1.3 -  Anwendungsbeispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<img style=\"float: right; margin:5px 0px 0px 10px\" src=\"img/audio.jpg\" width=\"400\">\n",
    "\n",
    "Diese Notebook baut auf die beiden Vorherigen auf, in denen der FIR und IIR Filterentwurf mit verschiedenen Methoden ausführlich behandelt wurde.\n",
    "\n",
    "Im Folgenden soll ein Praxisbeispiel für einer Filterantwendung mit konkreten Randbedingungen bearbeitet werden. Auf ein Audiosignal (akustik.wav, zu finden im Ordner 'data') sollen zunächst Störsignale aufaddiert werden, die anschließend mit verschiedenen Filtern wieder entfernt werden, um das ursprüngliche Signal wiederherzustellen. Dabei sollen die Vor- und Nachteile der verschiedenen Filtertypen aufgezeigt werden.\n",
    "\n",
    "Außerdem sollen einige grundlegende Python Module zur Verarbeitung speziell von Audiosignalen vorgestellt und angewendet werden.\n",
    "\n",
    "\n",
    "## Inhalt  \n",
    "\n",
    "<table style=\"width:256px; border: 1px solid black; display: inline-block\">\n",
    "  <tr>\n",
    "    <td  style=\"text-align:right\" width=64px><img src=\"img/IMG-Python.png\" style=\"float:left\"></td>\n",
    "      <td style=\"text-align:left\" width=256px>\n",
    "          <a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#intro'>1. Audiosignale in Python</a>\n",
    "    </td>\n",
    "  </tr>  \n",
    "    <tr>\n",
    "    <td  style=\"text-align:right\" width=64px><img src=\"img/IMG-fir.jpg\" style=\"float:left\"></td>\n",
    "      <td style=\"text-align:left\" width=256px>\n",
    "          <a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#fir'>2. FIR-Filterung</a>\n",
    "    </td>\n",
    "  </tr>  \n",
    "    <tr>\n",
    "    <td  style=\"text-align:right\" width=64px><img src=\"img/IMG-iir.jpg\" style=\"float:left\"></td>\n",
    "      <td style=\"text-align:left\" width=256px>\n",
    "          <a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#iir'>3. IIR-Filterung</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<a id='intro'></a><div><img src=\"img/IMG-Python.png\" style=\"float:left\"><h2 style=\"position: relative; top: 6px; left: 6px\">1. Audiosignale in Python</h2></div>\n",
    "\n",
    "#### 1.1 Import von Audiodateien\n",
    "\n",
    "Um ein Audiosignal zu bearbeiten, muss es zunächst geladen/importiert werden. Dafür werden drei verschiedene Methoden vorgestellt:\n",
    "\n",
    "```python\n",
    "path = 'data/akustik.wav'\n",
    "\n",
    "# 1. wavfile:\n",
    "from scipy.io import wavfile\n",
    "sr, audio = wavfile.read(path)\n",
    "\n",
    "# 2. wave:\n",
    "import wave\n",
    "wf = wave.open(path,'rb')\n",
    "audio = wf.readframes(1024)\n",
    "\n",
    "# 3. librosa:\n",
    "import librosa\n",
    "audio, sr = librosa.load(path)\n",
    "```\n",
    "\n",
    "In diesem Notebook verwenden wir die erste Option [`wavfile()`](https://docs.scipy.org/doc/scipy/reference/io.html?highlight=wavfile#module-scipy.io.wavfile), da es schon in dem Modul `scipy` integriert und somit installiert ist. Schauen Sie sich nun die Audioaufnahme `data/akustik.wav` im Zeit- und Frequenzbereich an. Importieren Sie dafür zuerst die dafür notwendigen Module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "# Importieren Sie aus scipy die Teilbibliothek \"fftpack\"\n",
    "# Importieren Sie aus  scipy.io die Teilbibliothek \"wavfile\"\n",
    "# Importieren Sie aus matplotlib die Teilbibliothek \"pyplot\" mit dem Alias \"plt\"\n",
    "# Importieren Sie das numpy-Modul mit dem Alias \"np\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "'''\n",
    "Beispiel: Audiodatei einlesen und visualisieren\n",
    "'''\n",
    "\n",
    "# Datei einlesen \n",
    "fs_Hz, audioSignal = wavfile.read('data/akustik.wav')  # Sample Rate, Audiosignal im Array-Form\n",
    "audioSignal = audioSignal/np.max(np.abs(audioSignal))  # Normalisierung\n",
    "\n",
    "# Signalparameter:\n",
    "signalLength = len(audioSignal)                 # Länge des Audiosignals\n",
    "T_s = signalLength/fs_Hz - 1/fs_Hz              # Zeit\n",
    "t_s = np.linspace(0, T_s, signalLength)         # Zeitbereich\n",
    "f_Hz = np.linspace(0, fs_Hz/2, signalLength//2) # Frequenzbereich\n",
    "\n",
    "# Spectrale\n",
    "audioSignal_fft = fftpack.fft(audioSignal)\n",
    "\n",
    "# plot\n",
    "plt.subplot(121)\n",
    "plt.title('Audiosignal im Zeitbereich')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Signalamplitude') \n",
    "plt.plot(t_s, audioSignal)\n",
    "plt.subplot(122)\n",
    "plt.title('%d Punkte FFT des Audiosignals' %signalLength)\n",
    "plt.xlabel('Frequenz [Hz]') \n",
    "plt.ylabel('|X(f)|') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(f_Hz, np.abs(audioSignal_fft[:int(signalLength/2)]))\n",
    "plt.gcf().set_size_inches(15, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 1.2 Abspielen von Audiodateien\n",
    "\n",
    "Die Ausgabe von Audiosignalen kann in Python auch mit unterschiedlichen externen Modulen realisiert werden. Falls Sie das Modul nicht installiert haben, können Sie dies via `pip install \"module\"` durchführen. Hier werden Ihnen drei mögliche Module mit Ihren individuellen Vorzügen vorgestellt:  \n",
    "\n",
    "- [`playsound`](https://pypi.org/project/playsound/)   \n",
    "Das PlaySound-Modul ist ein plattformübergreifendes Modul, das Audiodateien abspielen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound('data/akustik.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "- [`IPython.display`](https://ipython.org/ipython-doc/dev/api/generated/IPython.display.html)  \n",
    "Mit diesem Modul wird die Audiodatei mit einem Audioplayer geöffnet, der anschließend per Klick gestartet werden kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('data/akustik.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "- [`simpleaudio`](https://simpleaudio.readthedocs.io/en/latest/)  \n",
    "Das Modul ermöglicht es, sowohl wav-Dateien als auch NumPy-Arrays abgespielt zu können. Diese Eigenschaft ist für dieses Notebook sehr nützlich, weshalb im Weiteren auf `simpleaudio` zurückgegriffen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: wav-Dateien abspielen\n",
    "\n",
    "# Datei einlesen\n",
    "wave_obj = sa.WaveObject.from_wave_file('data/akustik.wav')\n",
    "\n",
    "# abspielen\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: NumPy-Arrays (Audiosignal) abspielen\n",
    "\n",
    "# Datei ablesen \n",
    "fs_Hz, audioSignal = wavfile.read('data/akustik.wav')\n",
    "\n",
    "# abspielen\n",
    "play_obj = sa.play_buffer(audioSignal, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: NumPy-Arrays (Sinussignal) abspielen\n",
    "\n",
    "# Sinussignal erzeugen\n",
    "t_s = np.linspace(0, 3, 8000)\n",
    "sine = np.sin(440 * np.pi * t_s)\n",
    "\n",
    "# Werte im 16-Bit-Bereich konvertieren\n",
    "sound = sine * (2**15 - 1) / np.max(sine)\n",
    "sound = sound.astype(np.int16)\n",
    "\n",
    "# abspielen\n",
    "play_obj = sa.play_buffer(sound, 1, 2, 8000)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 1.3 Signale bearbeiten / Störsignal erstellen\n",
    "\n",
    "Wenn das Audiosignal als numpy-Array vorliegt, kann das Signal sehr leicht bearbeitet werden. Zuerst soll dafür auf die Audiodatei `akustik.wav` ein Sinus mit der Frequenz von 440 Hz addiert werden. Dadurch erhält die Audiodatei ein Störsignal, welches Sie danach wieder davon zu entfernen versuchen. Da gleich das Signal zudem gefenstert werden soll, wird noch das Modul `signal` importiert, um daraus [get_window()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.get_window.html) zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "# Importieren Sie aus scipy die Teilbibliothek \"signal\" \n",
    "from scipy import signal, fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "'''\n",
    "Beispiel: Signal addieren, visualisieren und abspielen\n",
    "'''\n",
    "\n",
    "# Datei einlesen (originales Audiosignal) und Amplitude normalisieren:\n",
    "fs_Hz, audioSignal = wavfile.read('data/akustik.wav')\n",
    "audioSignal = audioSignal/np.max(np.abs(audioSignal)) \n",
    "\n",
    "# Initiale Daten\n",
    "fsin_Hz = 440   # Sinusfrequenz\n",
    "signalLength = len(audioSignal)  # Länge des Audiosignals\n",
    "T_s = signalLength/fs_Hz - 1/fs_Hz    # Zeitraum\n",
    "t_s = np.linspace(0, T_s, signalLength) # Zeitbereich\n",
    "f_Hz = np.linspace(0, fs_Hz/2, signalLength//2) # Frequenzbereich\n",
    "\n",
    "# Sinussignale erstellen\n",
    "sine = 1/2 * np.sin(fsin_Hz * 2*np.pi * t_s)\n",
    "sine_fft = fftpack.fft(sine)\n",
    "\n",
    "# Signal zur Filterung\n",
    "corruptedAudioSignal = audioSignal + sine  # Additives Signal\n",
    "corruptedAudioSignal_fft = fftpack.fft(corruptedAudioSignal)  # Frequenzgang\n",
    "\n",
    "# Fensterung (optional)\n",
    "window = signal.get_window('hanning', signalLength)\n",
    "corruptedAudioSignal_windowed = corruptedAudioSignal * window\n",
    "\n",
    "# plot\n",
    "plt.subplot(221)\n",
    "plt.title('Störsignal im Zeitbereich')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.xlim(0, 0.1)\n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(-1, 1)\n",
    "plt.plot(t_s, sine)\n",
    "plt.subplot(222)\n",
    "plt.title('Störsignal im Frequenzbereich')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 500)\n",
    "plt.plot(f_Hz, np.abs(sine_fft[:signalLength//2]))\n",
    "plt.subplot(223)\n",
    "plt.title('Audiosignal mit Störung im Zeitbereich')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t_s, corruptedAudioSignal_windowed)\n",
    "plt.subplot(224)\n",
    "plt.title('Audiosignal mit Störung im Frequenzbereich')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 500)\n",
    "plt.plot(f_Hz, np.abs(corruptedAudioSignal_fft[:signalLength//2]))\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "# Abspielen\n",
    "sound = (corruptedAudioSignal * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "# Abspielen\n",
    "sound = (corruptedAudioSignal_windowed * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal_windowed))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Mit `corruptedAudioSignal` beziehungsweise `corruptedAudioSignal_windowed` wurde jetzt ein mit einem Sinuston gestörtes Audiosignal erzeugt. Im Folgenden wird nun versucht, mittels der in Notebook 1.1 und 1.2 kennengelernten Filter diese Störung zu filtern und wieder ein dem Original ähnliches Audiosignal zu rekonstruieren.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<a id='fir'></a><div><img src=\"img/IMG-fir.jpg\" style=\"float:left\"><h2 style=\"position: relative; top: 6px; left: 6px\">2. FIR-Filterung </h2></div>\n",
    "\n",
    "#### 2.1 FIR-Filter mittels IDFT\n",
    "\n",
    "Wie in Kapitel 1.1 wird zuerst ein Bandsperrfilter mittels IDFT verwendet und entworfen, um das Sinussignal aus dem Audiosignal zu entfernen. Der Filter soll dabei eine Bandbreite von 60 Hz haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "\n",
    "'''\n",
    "Beispiel: Entfernen von Signalen mittels selbst definierten FIR-Bandsperrfilters \n",
    "'''\n",
    "\n",
    "# Berechnung des FIR Filters:\n",
    "\n",
    "bw_Hz = 100  # Bandbreite des Sperrbereiches\n",
    "fcLower_Hz = fsin_Hz - bw_Hz/2\n",
    "fcUpper_Hz = fsin_Hz + bw_Hz/2\n",
    "fftLength = 2048\n",
    "f_Hz = np.linspace(0, fs_Hz, fftLength)\n",
    "# Definition des idealen Frequenzganges:\n",
    "H = np.where((f_Hz > fcLower_Hz) & (f_Hz < fcUpper_Hz) \n",
    "             | (f_Hz > fs_Hz - fcUpper_Hz) & (f_Hz < fs_Hz - fcLower_Hz), 0, 1)  \n",
    "# IFFT und shift:\n",
    "h = np.fft.ifftshift(fftpack.ifft(H, fftLength))  \n",
    "\n",
    "# Filterkern aus der Impulsantwort ausschneiden und Fenstern:\n",
    "filterLength = 1500;\n",
    "window = signal.get_window('hanning', filterLength+1)\n",
    "filterKernel = np.real(h[(fftLength - filterLength)//2:(fftLength + filterLength)//2 + 1])*window\n",
    "k = np.arange(0, filterKernel.size)\n",
    "\n",
    "# Synthese des ist-Filters:\n",
    "H_ist = np.abs(fft.fft(filterKernel, fftLength))\n",
    "\n",
    "# Graphische Darstellung\n",
    "plt.subplot(131)\n",
    "plt.title('Idealer Amplitudenfrequenzgang \\n des Bandpasses')\n",
    "plt.xlabel('Frequenz [Hz]') \n",
    "plt.ylabel('$H(e^{j\\Omega})$')\n",
    "plt.xlim([0,1200])\n",
    "plt.plot(f_Hz, H)\n",
    "plt.subplot(132)\n",
    "plt.title('Maskierte und gefensterte \\n Impulsantwort des Bandsperrfilters')\n",
    "plt.xlabel('Sample Index k') \n",
    "plt.stem(k, filterKernel, use_line_collection=True)\n",
    "plt.subplot(133)\n",
    "plt.title('Tatsächlicher Amplitudenfrequenzgang \\n des Bandsperrfilters')\n",
    "plt.xlabel('Frequenz [Hz]') \n",
    "plt.ylabel('$|H(e^{j\\Omega})|$') \n",
    "plt.plot(f_Hz, H_ist)\n",
    "plt.xlim([0,1200])\n",
    "plt.subplots_adjust(left=0.1, right=2, top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "\n",
    "# Filterung\n",
    "corruptedAudioSignal_filtered = signal.convolve(corruptedAudioSignal, filterKernel, 'same') # Faltung\n",
    "corruptedAudioSignal_filtered_fft = fftpack.fft(corruptedAudioSignal_filtered)\n",
    "\n",
    "# Plot\n",
    "fPlot_Hz = np.linspace(0, fs_Hz, signalLength)\n",
    "plt.subplot(121)\n",
    "plt.title('Audiosignal nach Bandsperrfilterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Signalamplitude') \n",
    "plt.plot(t_s, corruptedAudioSignal_filtered)\n",
    "plt.subplot(122)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [Hz]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(corruptedAudioSignal_filtered_fft[:signalLength//2]))\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (corruptedAudioSignal_filtered * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 2.2 FIR-Filter mittels __firwin()__  \n",
    "Für solche Anwendungen können wir aber auch die vorhandenen Filter wie [`signal.firwin()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.firwin.html) in __[`scipy.signal`](https://docs.scipy.org/doc/scipy/reference/signal.html)__ direkt benutzen. Ändern Sie dabei die Ordnung (sie können dafür auch eine for-Schleife mit logarithmisch ansteigender Ordnungszahl implementieren), bis das Ergebnis dem der IDFT ähnelt. <br> _Hinweis_: die Ordnungszahl $n$ kann gerne größer 1000 sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "\n",
    "'''\n",
    "Aufgabe: Entfernen von Signalen mittels signal.firwin() \n",
    "'''\n",
    "# Parameter\n",
    "bw_Hz = 60  # Bandbreite\n",
    "filterOrder = 5001  # Ordnung\n",
    "wPass_Hz = [(fsin_Hz-bw_Hz/2), (fsin_Hz+bw_Hz/2)]\n",
    "\n",
    "# Filterung mit Fenster\n",
    "h_fir = signal.firwin(filterOrder, wPass_Hz, window='hanning', fs=fs_Hz)\n",
    "H_fir = fftpack.fft(h_fir, signalLength)  # Spektral des Filters\n",
    "corruptedAudioSignal_filtered = signal.convolve(corruptedAudioSignal_windowed, h_fir, 'same')  # Faltung\n",
    "corruptedAudioSignal_filtered_fft = fftpack.fft(corruptedAudioSignal_filtered)  # Spektral des Signals\n",
    "\n",
    "# plot\n",
    "fPlot_Hz\n",
    "plt.subplot(221)\n",
    "plt.title('Impulsantwort des Filters')\n",
    "plt.xlabel('Sample Nummer') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(h_fir)\n",
    "plt.subplot(222)\n",
    "plt.title('Spektral des Filters')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(H_fir[:signalLength//2]))\n",
    "plt.subplot(223)\n",
    "plt.title('Audiosignal nach Bandsperrfilterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t_s, corruptedAudioSignal_filtered)\n",
    "plt.subplot(224)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(corruptedAudioSignal_filtered_fft[:signalLength//2]))\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (corruptedAudioSignal_filtered * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Um einen Bandsperrfilter mit hohem Knick und engem Frequenzbereich zu erzeugen, um nur das Sinussignal zu entfernen, benötigt der FIR-Filter eine große Ordnungszahl. Das bedeutet, dass man für die Umsetzung des Filters viel Speicherplatz benötigt und einen goßen Rechenaufwand hat, was für eine niedrige Effizienz spricht.  \n",
    "\n",
    "Um zu analysieren, ob IIR-Filter eine bessere Alternative darstellen, wenn es um effizientes Filterdesign geht, soll nun im nächsten Kapitel dasselbe Signal `corruptedAudioSignal` bzw. `corruptedAudioSignal_windowed` mittels der in Notebook 1.2 kennengelernten Filter und Filterdesign bereinigt werden.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<a id='iir'></a><div><img src=\"img/IMG-iir.jpg\" style=\"float:left\"><h2 style=\"position: relative; top: 6px; left: 6px\">3. IIR-Filterung </h2></div>\n",
    "\n",
    "#### 3.1 Butterworth Filter\n",
    "\n",
    "Zunächst soll ein Butterworth-Filter mit 10. Ordnung und einer Bandbreite $bw = 60$ Hz entworfen werden. Dazu wird, wie in Kapitel 1.2, das Objekt [`signal.butter()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html) zur Erzeugung der Filterkoeffizienten verwendet. Geben Sie sich nun aber mittels `output=sos` die \"second-order sections\" aus, da mit diesen diekt über das Objekt [`signal.sosfilt()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.sosfilt.html) eine Filterung des Signals durchgeführt werden kann.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "'''\n",
    "Beispiel: Entfernen von Signalen mittels IIR-Bandsperrfilters (Butterworth)\n",
    "'''\n",
    "# Parameter\n",
    "bw_Hz = 60  # Bandbreite des Filters\n",
    "filterOrder =  10  # Ordnung des IIR-Filters\n",
    "wPass_Hz = [fsin_Hz-bw_Hz/2, fsin_Hz+bw_Hz/2]  # Frequenzbereich des Sperrbands\n",
    "\n",
    "# Filterung \n",
    "sos = signal.butter(filterOrder, wPass_Hz, 'bs', analog=False, fs=fs_Hz, output='sos')\n",
    "w, H_butt = signal.sosfreqz(sos, int(signalLength/2), fs=fs_Hz)\n",
    "\n",
    "\n",
    "corruptedAudioSignal_filtered = signal.sosfilt(sos, corruptedAudioSignal)\n",
    "corruptedAudioSignal_filtered_fft = fftpack.fft(corruptedAudioSignal_filtered)\n",
    "\n",
    "# Graphische Darstellung\n",
    "plt.subplot(311)\n",
    "plt.title('Frequenzgang des Butterworth Filters mit Ordnung=%d' %filterOrder)\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(H_butt[:int(signalLength/2)]))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.title('Audiosignal nach Filterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t_s, corruptedAudioSignal_filtered)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(corruptedAudioSignal_filtered_fft[:signalLength//2]))\n",
    "\n",
    "plt.gcf().set_size_inches(8, 16)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (corruptedAudioSignal_filtered * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Um nun den Butterworth-Filter mit Spezifikationen zu erzeugen, soll nun der Filterentwurf mit Ordnungsselektion durchgeführt werden. Dazu wird das Objekt [signal.buttord()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.buttord.html) verwendet. Dessen Dämpfung soll im Sperrbereich von $fsin\\_Hz-bw$ bis $fsin\\_Hz+bw$ Hz mindestens 60 dB betragen, während die Dämpfung im Durchlassbereich (außerhalb von [$fsin\\_Hz-bw-10, fsin\\_Hz+bw+10$] Hz) innerhalb von -10 dB liegen soll.<br>\n",
    "Die Bandbreite soll dabei wieder $bw = 60$ Hz betragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "'''\n",
    "Aufgabe: Entfernen von Signalen mittels IIR-Bandsperrfilters (Butterworth)\n",
    "'''\n",
    "# Ordnungsselektion\n",
    "bw_Hz = 60  # Bandbreite\n",
    "optOrder, wPass_rad = signal.buttord([fsin_Hz-bw_Hz/2-10, fsin_Hz+bw_Hz/2+10], [fsin_Hz-bw_Hz/2, fsin_Hz+bw_Hz/2], 10, 60, False, fs_Hz)\n",
    "\n",
    "# Erzeugen des Bandsperrfilters \n",
    "sos = signal.butter(optOrder, wPass_rad, 'bs', False, 'sos', fs_Hz)\n",
    "w, H_butt = signal.sosfreqz(sos, int(signalLength/2), fs=fs_Hz)\n",
    "\n",
    "# Filterung \n",
    "corruptedAudioSignal_filtered = signal.sosfilt(sos, corruptedAudioSignal)\n",
    "corruptedAudioSignal_filtered_fft = fftpack.fft(corruptedAudioSignal_filtered)\n",
    "\n",
    "# plot\n",
    "plt.subplot(311)\n",
    "plt.title('Frequenzgang des Butterworth Filters mit Ordnung=%d' %optOrder)\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(H_butt[:int(signalLength/2)]))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.title('Audiosignal nach Filterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t_s, corruptedAudioSignal_filtered)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(corruptedAudioSignal_filtered_fft[:signalLength//2]))\n",
    "plt.gcf().set_size_inches(8, 16)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (corruptedAudioSignal_filtered * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Im Titel der ersten Graphik wird die Ordnungszahl ausgegeben. Diese ist um mindestens 2 Zehnerpotenzen geringer als die des FIR-Filters. Das bedeutet, dass man für die Umsetzung des IIR-Filters viel weniger Speicherplatz und Rechenleistung benötigt, was die Anwendung des IIR-Filters in diesem Fall viel effizienter macht. \n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Chebyshev Filter\n",
    "\n",
    "Entwerfen Sie zum Schluss noch einen Chebyshev-Filter vom Typ 2 zur Bereinigung des Audiosignals. Auch hier soll die Ordnungsselektion angewendet werden, wofür das Objekt [`signal.cheb2ord()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.cheb2ord.html) zur Verfügung steht.<br>\n",
    "Die Bedingungen an den Filter sind wie in 3.1: Die Dämpfung soll im Sperrbereich von $fsin\\_Hz-bw$ bis $fsin\\_Hz+bw$ Hz mindestens 60 dB betragen, während die Dämpfung im Durchlassbereich (außerhalb von [$fsin\\_Hz-bw-10, fsin\\_Hz+bw+10$] Hz) innerhalb von -10 dB liegen soll.<br>\n",
    "Die Bandbreite soll dabei wieder $bw = 60$ Hz betragen.\n",
    "\n",
    "Für die Berechnung des Filters soll nun aber das Objekt [`signal.cheby2()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.cheby2.html) verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "'''\n",
    "Aufgabe: Entfernen von Signalen mittels IIR-Bandsperrfilters (Chebyshev II mit Ordnungselektion)\n",
    "'''\n",
    "\n",
    "# Ordnungselektion\n",
    "bw_Hz = 60  # Bandbreite\n",
    "optOrder, wPass_rad = signal.cheb2ord([fsin_Hz-bw_Hz/2-10, fsin_Hz+bw_Hz/2+10], [fsin_Hz-bw_Hz/2, fsin_Hz+bw_Hz/2], 10, 60, False, fs_Hz)\n",
    "\n",
    "# Erzeugen des Bandsperrfilters \n",
    "sos = signal.cheby2(optOrder, 60, wPass_rad, 'bs', False, 'sos', fs_Hz)\n",
    "w, H_cheby = signal.sosfreqz(sos, int(signalLength/2), fs=fs_Hz)\n",
    "\n",
    "# Filterung\n",
    "corruptedAudioSignal_filtered = signal.sosfilt(sos, corruptedAudioSignal)\n",
    "corruptedAudioSignal_filtered_fft = fftpack.fft(corruptedAudioSignal_filtered)\n",
    "\n",
    "# plot\n",
    "plt.subplot(311)\n",
    "plt.title('Frequenzgang des Chebyshev-II Filters mit Ordnung=%d' %optOrder)\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(H_butt[:int(signalLength/2)]))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.title('Audiosignal nach Filterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t_s, corruptedAudioSignal_filtered)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(fPlot_Hz[:signalLength//2], np.abs(corruptedAudioSignal_filtered_fft[:signalLength//2]))\n",
    "plt.gcf().set_size_inches(8, 16)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (corruptedAudioSignal_filtered * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "Zum Schluss soll nun das bearbeitete Audiosignal gespeichert werden. Dazu kann das Objekt [`wavfile.write()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html) verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung\n",
    "'''\n",
    "Beispiel: Daten in eine wav-Datei schreiben\n",
    "'''\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from playsound import playsound\n",
    "\n",
    "# Pfad einer neuen wav-Datei bestimmen\n",
    "file_path = 'data/akustik_filtered.wav'\n",
    "# Audiodaten in 16-Bit-Format konvertieren\n",
    "data = (corruptedAudioSignal_filtered * (2**15 - 1) / np.max(np.abs(corruptedAudioSignal_filtered))).astype(np.int16)\n",
    "# Audiodaten schreiben\n",
    "wavfile.write(file_path, fs_Hz, data)\n",
    "\n",
    "# Testen, ob die Daten erfolgreich gespeichert wurde\n",
    "playsound('data/akustik_filtered.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "1. Titelbild von [Encarni Mármol](https://lda-audiotech.com/en/2018/10/30/how-to-digitize-analog-audio/)  \n",
    "2. [Play sound in Python](https://pythonbasics.org/python-play-sound/)\n",
    "---\n",
    "<div>Notebook erstellt von Arne-Lukas Fietkau, Yifei Li  und <a href=\"mailto:christoph.wagner@tu-dresden.de?Subject=Frage%20zu%20Jupyter%20Notebook%201.3%20Anwendungsbeispiel\" target=\"_top\">Christoph Wagner</a></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
